{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# Federated TF Keras TinyImageNet Tutorial\n",
    "## Using low-level Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b6f3e",
   "metadata": {},
   "source": [
    "# Long-Living entities update\n",
    "\n",
    "* We now may have director running on another machine.\n",
    "* We use Federation API to communicate with Director.\n",
    "* Federation object should hold a Director's client (for user service)\n",
    "* Keeping in mind that several API instances may be connacted to one Director.\n",
    "\n",
    "\n",
    "* We do not think for now how we start a Director.\n",
    "* But it knows the data shape and target shape for the DataScience problem in the Federation.\n",
    "* Director holds the list of connected envoys, we do not need to specify it anymore.\n",
    "* Director and Envoys are responsible for encrypting connections, we do not need to worry about certs.\n",
    "\n",
    "\n",
    "* Yet we MUST have a cert to communicate to the Director.\n",
    "* We MUST know the FQDN of a Director.\n",
    "* Director communicates data and target shape to the Federation interface object.\n",
    "\n",
    "\n",
    "* Experiment API may use this info to construct a dummy dataset and a `shard descriptor` stub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f509021",
   "metadata": {},
   "source": [
    "### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895288d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9d870",
   "metadata": {},
   "source": [
    "## Connect to the Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e356aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'api'\n",
    "cert_dir = 'cert'\n",
    "director_node_fqdn = 'localhost'\n",
    "# 1) Run with API layer - Director mTLS \n",
    "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
    "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
    "# api_certificate = f'{cert_dir}/{client_id}.crt'\n",
    "# api_private_key = f'{cert_dir}/{client_id}.key'\n",
    "\n",
    "# federation = Federation(client_id=client_id, director_node_fqdn=director_node_fqdn, director_port='50051',\n",
    "#                        cert_chain=cert_chain, api_cert=api_certificate, api_private_key=api_private_key)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(client_id=client_id, director_node_fqdn=director_node_fqdn, director_port='50051', tls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0150bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639d734",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e64ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36710220",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67057a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf91077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def train_transform(img):\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    if img.mode == 'L':\n",
    "        original = tf.constant(array)\n",
    "        array = tf.image.grayscale_to_rgb(original)\n",
    "    array = tf.reshape(array, array.shape)\n",
    "    \n",
    "    return array\n",
    "\n",
    "\n",
    "def val_transform(img):\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    if img.mode == 'L':\n",
    "        original = tf.constant(array)\n",
    "        array = tf.image.grayscale_to_rgb(original)\n",
    "    array = tf.reshape(array, array.shape)\n",
    "    return array\n",
    "\n",
    "\n",
    "class TransformedDataset(tf.keras.utils.Sequence):\n",
    "    \"\"\"Image Person ReID Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, batch_size, transform=None):\n",
    "        \"\"\"Initialize Dataset.\"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Length of dataset.\"\"\"\n",
    "        return math.ceil(len(self.dataset) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        first_id = index * self.batch_size\n",
    "        last_id = (index + 1) * self.batch_size\n",
    "        if len(self.dataset) < last_id:\n",
    "            last_id = len(self.dataset)\n",
    "    \n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for i in range(first_id, last_id):\n",
    "            img, label = self.dataset[i]\n",
    "            img = self.transform(img) if self.transform else None\n",
    "            batch_x.append(img)\n",
    "            batch_y.append(label)\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3678256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyImageNetDataset(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        self.train_bs = kwargs['train_bs']\n",
    "        self.valid_bs = kwargs['valid_bs']\n",
    "    \n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "        \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        \n",
    "        self.train_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('train'),\n",
    "            batch_size=self.train_bs,\n",
    "            transform=train_transform\n",
    "        )\n",
    "        self.valid_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('val'),\n",
    "            batch_size=self.valid_bs,\n",
    "            transform=val_transform\n",
    "        )\n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        return self.train_set\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        return self.valid_set\n",
    "    \n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa141c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e70481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "num_classes = 200\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "\n",
    "# model = Sequential([\n",
    "# #     layers.experimental.preprocessing.Rescaling(1./255),\n",
    "# #     data_augmentation,  \n",
    "#     layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(512, activation='relu'),\n",
    "#     layers.Dense(num_classes)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(200)\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(64, 64, 3))\n",
    "#     x = data_augmentation(inputs)\n",
    "#     x = norm_layer(x)\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "# x = tf.keras.layers.Dropout(0.1)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcf631",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = 32\n",
    "valid_bs = 32\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(train_bs, 64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5976ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_interface = TaskInterface()\n",
    "\n",
    "\n",
    "@task_interface.register_fl_task(model='model', data_loader='train_dataset',\n",
    "                                 device='device', optimizer='optimizer')     \n",
    "def train(model, train_dataset, optimizer, device, loss_fn=loss_fn, warmup=False):    \n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        y = tf.convert_to_tensor(y_batch_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch_train, training=True)  # Forward pass\n",
    "\n",
    "            loss = loss_fn(y, y_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update metrics\n",
    "        train_acc_metric.update_state(y, y_pred)\n",
    "    \n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "    return {'train_acc': train_acc, 'loss': loss}\n",
    "\n",
    "\n",
    "@task_interface.register_fl_task(model='model', data_loader='val_dataset', device='device')     \n",
    "def validate(model, val_dataset, device):\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        y = tf.convert_to_tensor(y_batch_val)\n",
    "        # Compute predictions\n",
    "        y_pred = model(x_batch_val, training=False)\n",
    "        # Update the metrics.\n",
    "        val_acc_metric.update_state(y, y_pred)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    \n",
    "    return {'validation_accuracy': val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05028841",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = TinyImageNetDataset(train_bs=train_bs, valid_bs=valid_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e158c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for local tests\n",
    "# from tinyimagenet_shard_descriptor import TinyImageNetShardDescriptor\n",
    "\n",
    "\n",
    "# sd = TinyImageNetShardDescriptor('tinyimagenet_data')\n",
    "# fed_dataset.shard_descriptor = sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239de879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run local test\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "# for i in range(5):\n",
    "#     print(i)\n",
    "#     res = train(model=model, optimizer=optimizer, device='CPU', train_dataset=fed_dataset.get_train_loader())\n",
    "#     print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare data for local tests\n",
    "\n",
    "# !pip install matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def draw(history, epochs):\n",
    "#     acc = history.history['accuracy']\n",
    "#     val_acc = history.history['val_accuracy']\n",
    "\n",
    "#     loss = history.history['loss']\n",
    "#     val_loss = history.history['val_loss']\n",
    "\n",
    "#     epochs_range = range(epochs)\n",
    "\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "#     plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.title('Training and Validation Accuracy')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(epochs_range, loss, label='Training Loss')\n",
    "#     plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "#     plt.legend(loc='upper right')\n",
    "#     plt.title('Training and Validation Loss')\n",
    "#     plt.show()\n",
    "\n",
    "# IMG_SIZE = 64\n",
    "# resize_and_rescale = tf.keras.Sequential([\n",
    "#   layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "# #   layers.experimental.preprocessing.Rescaling(1./255)\n",
    "# ])\n",
    "    \n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "#   layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "#   layers.RandomCrop(IMG_SIZE, IMG_SIZE),\n",
    "#   layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "#   layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "# ])\n",
    "\n",
    "# norm_layer = tf.keras.layers.Normalization(\n",
    "#     mean=[0.485, 0.456, 0.406],\n",
    "#     variance=[0.229, 0.224, 0.225]\n",
    "# )\n",
    "\n",
    "# def get_model(lr=0.001):\n",
    "# #     model = Sequential([\n",
    "# # #         layers.experimental.preprocessing.Rescaling(1./255, input_shape=(64, 64, 3)),\n",
    "# #         data_augmentation,\n",
    "# #         layers.Normalization(mean=[0.485, 0.456, 0.406], variance=[0.229, 0.224, 0.225]),\n",
    "# #         layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "# #         layers.MaxPooling2D(),\n",
    "# #         layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "# #         layers.MaxPooling2D(),\n",
    "# #         layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "# #         layers.MaxPooling2D(),\n",
    "# #         layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "# #         layers.MaxPooling2D(),\n",
    "# #         layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "# #         layers.MaxPooling2D(),\n",
    "# #         layers.Flatten(),\n",
    "# #         layers.Dense(512, activation='relu'),\n",
    "# #         layers.Dense(num_classes)\n",
    "# #     ])\n",
    "\n",
    "# #     self.model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "# #     self.model.requires_grad_(False)\n",
    "# #     self.model.classifier[1] = torch.nn.Linear(in_features=1280, \\\n",
    "# #                     out_features=200, bias=True)\n",
    "    \n",
    "#     base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "#         include_top=False\n",
    "#     )\n",
    "#     base_model.trainable = False\n",
    "    \n",
    "# # #     base_model.summary()\n",
    "#     preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    \n",
    "#     global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "#     prediction_layer = tf.keras.layers.Dense(200)\n",
    "    \n",
    "#     inputs = tf.keras.Input(shape=(64, 64, 3))\n",
    "#     x = data_augmentation(inputs)\n",
    "# #     x = norm_layer(x)\n",
    "# #     x = preprocess_input(inputs)\n",
    "#     x = base_model(x, training=False)\n",
    "#     x = global_average_layer(x)\n",
    "#     x = tf.keras.layers.Dropout(0.1)(x)\n",
    "#     outputs = prediction_layer(x)\n",
    "#     model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "#     optimizer = tf.keras.optimizers.Adam()\n",
    "#     model.build(input_shape=[train_bs, 64, 64, 3])\n",
    "#     model.compile(\n",
    "#         optimizer=optimizer,\n",
    "#         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#         metrics=['accuracy'],\n",
    "#     )\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run local test\n",
    "\n",
    "# models = {}\n",
    "# for lr in [0.001]:\n",
    "#     model = get_model(lr)\n",
    "#     models[lr] = model\n",
    "#     epochs=60\n",
    "#     print(f'{lr=}')\n",
    "#     history = model.fit(\n",
    "#       fed_dataset.get_train_loader(),\n",
    "#       validation_data=fed_dataset.get_valid_loader(),\n",
    "#       epochs=epochs\n",
    "#     )\n",
    "#     draw(history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f097cdc5",
   "metadata": {},
   "source": [
    "### Register model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a8cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\n",
    "model_interface = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebf2d",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'tinyimagenet_test_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b44de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(\n",
    "    model_provider=model_interface, \n",
    "    task_keeper=task_interface,\n",
    "    data_loader=fed_dataset,\n",
    "    rounds_to_train=10,\n",
    "    opt_treatment='CONTINUE_GLOBAL'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}